{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import tqdm\n",
    "from torch import nn\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "np.set_printoptions(threshold=200)\n",
    "torch.set_printoptions(edgeitems=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"pickle/pickle_r_all\", \"rb\") as f:\n",
    "    r = pickle.load(f)\n",
    "with open(\"pickle/pickle_p_all\", \"rb\") as f:\n",
    "    p = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = r.data_c[r.data_c['date']>'2024-07-01']\n",
    "data = r.data_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Class.LearningDataProcessor import RacingDataProcessor\n",
    "from Class.Model import HorseRaceModel\n",
    "from Class.LearningModule import LearningModule\n",
    "from Func.Deeplearning_func import set_criterion\n",
    "from Func.Deeplearning_func import log_func\n",
    "from Func.Deeplearning_func import create_predictionTable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"unsamble_pickle\"\n",
    "folder_list = os.listdir(base_path)\n",
    "folder_list\n",
    "\n",
    "dfs = [pd.read_pickle(base_path+'/'+folder_name) for folder_name in folder_list]\n",
    "dfs = [df.rename(columns={'pred_0':f'pred_{5*i}',\n",
    "                  'pred_1':f'pred_{5*i+1}',\n",
    "                  'pred_2':f'pred_{5*i+2}',\n",
    "                  'pred_3':f'pred_{5*i+3}',\n",
    "                  'pred_4':f'pred_{5*i+4}',\n",
    "                  'rank_0':f'ranking_{5*i}',\n",
    "                  'rank_1':f'ranking_{5*i+1}',\n",
    "                  'rank_2':f'ranking_{5*i+2}',\n",
    "                  'rank_3':f'ranking_{5*i+3}',\n",
    "                  'rank_4':f'ranking_{5*i+4}',\n",
    "                  }) for i ,df in enumerate(dfs)]\n",
    "df_list = data.reset_index()\n",
    "for i, df in enumerate(dfs):\n",
    "    pred = [column for column in df.columns if 'pred' in column]\n",
    "    ranking = [column for column in df.columns if 'ranking' in column]\n",
    "    df = df[pred+ranking+['date', 'horse_id']]\n",
    "    df_list = df_list.merge(df, on=['date', 'horse_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = [column for column in df_list.columns if 'ranking' in column]\n",
    "df_list['ranking_mean'] =  df_list[ranking].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  df_list[['index','着順','人気','単勝','ranking_mean','horse_id','date','ranking_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test[test['ranking_mean']<1.5]\n",
    "# test2 = test2[test2['単勝']>8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26501296335225283"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test2[test2['着順']==1])/len(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6887394015836312"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test['index'].unique())/len(test2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keiba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
